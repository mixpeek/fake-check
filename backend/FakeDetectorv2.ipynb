{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2qqxWyGif1s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c57b075b-24f1-4049-f3f2-45a87f3a81dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 0: Upgrading pip ---\n",
            "\n",
            "--- Step 1: Removing conflicting Colab defaults ---\n",
            "\n",
            "--- Step 2: Installing critical base packages ---\n",
            "\n",
            "--- Step 2.5: Installing stable google-api-core ---\n",
            "\n",
            "--- Verification 1: Base packages ---\n",
            "NumPy version: 1.26.4\n",
            "Pillow version: 9.5.0\n",
            "Protobuf version: 4.25.7\n",
            "google-api-core version: 2.11.1\n",
            "‚úÖ PIL.ImageFont imported successfully\n",
            "\n",
            "--- Step 3: Installing PyTorch stack ---\n",
            "\n",
            "--- Step 4: Installing Transformers stack ---\n",
            "\n",
            "--- Step 5: Installing ftfy and open-clip ---\n",
            "\n",
            "--- Verification 2: Torch and vision stack ---\n",
            "‚úÖ PyTorch version: 2.2.1+cu118\n",
            "‚úÖ open-clip imported successfully\n",
            "\n",
            "--- Step 6: Installing Google Generative AI ---\n",
            "\n",
            "--- Step 7: Pre-installing Whisper dependencies ---\n",
            "\n",
            "--- Step 8: Installing OpenAI Whisper ---\n",
            "\n",
            "--- Step 9: Installing other utilities ---\n",
            "\n",
            "--- Step 10: Final version enforcement ---\n",
            "\n",
            "--- FINAL VERIFICATION ---\n",
            "‚úÖ PIL: 9.5.0 (expected: 9.5.0)\n",
            "    ‚úÖ PIL.ImageFont works with Pillow 9.5.0\n",
            "‚úÖ numpy: 1.26.4 (expected: 1.26.4)\n",
            "‚úÖ google.api_core: 2.11.1 (expected: 2.11.1)\n",
            "‚úÖ torch: 2.2.1+cu118 (expected: 2.2.1+cu118)\n",
            "‚úÖ transformers: 4.40.2\n",
            "‚úÖ huggingface_hub: 0.31.4\n",
            "‚úÖ open_clip: N/A\n",
            "‚úÖ whisper: 20231117 (expected: 20231117)\n",
            "‚úÖ cv2: 4.9.0\n",
            "‚ö†Ô∏è google.generativeai: N/A (expected: 0.5.2)\n",
            "\n",
            "==================================================\n",
            "‚úÖ Environment setup targeted critical versions. Check ‚ö†Ô∏è for non-critical or resolved versions.\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Cell 00: Robust Environment Setup with Force Installation\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "import importlib\n",
        "\n",
        "# 0. Function to force package installation with system override\n",
        "def force_install_package(package_spec):\n",
        "    \"\"\"Force installation ignoring system packages\"\"\"\n",
        "    subprocess.check_call([sys.executable, '-m', 'pip', 'install',\n",
        "                          '--force-reinstall', '--no-deps', package_spec])\n",
        "\n",
        "def install_with_deps(package_spec):\n",
        "    \"\"\"Install package with dependencies\"\"\"\n",
        "    subprocess.check_call([sys.executable, '-m', 'pip', 'install',\n",
        "                          '--force-reinstall', package_spec])\n",
        "\n",
        "# 1. Upgrade pip first\n",
        "print(\"--- Step 0: Upgrading pip ---\")\n",
        "subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--upgrade', 'pip'])\n",
        "\n",
        "# 2. CRITICAL: Uninstall Colab's default packages that conflict\n",
        "print(\"\\n--- Step 1: Removing conflicting Colab defaults ---\")\n",
        "# Uninstall packages that Colab pre-installs which conflict with our requirements\n",
        "subprocess.run([sys.executable, '-m', 'pip', 'uninstall', '-y',\n",
        "               'Pillow', 'numpy', 'protobuf'], capture_output=True)\n",
        "\n",
        "# 3. Install core dependencies with explicit force\n",
        "print(\"\\n--- Step 2: Installing critical base packages ---\")\n",
        "# Install NumPy 1.26.4 first as many packages depend on it\n",
        "force_install_package('numpy==1.26.4')\n",
        "\n",
        "# Install Pillow 9.5.0 to fix the is_directory error\n",
        "force_install_package('Pillow==9.5.0')\n",
        "\n",
        "# Install protobuf early (use 4.x since MediaPipe is removed)\n",
        "force_install_package('protobuf==4.25.3')\n",
        "\n",
        "# *** NEW STEP: Install a stable google-api-core ***\n",
        "print(\"\\n--- Step 2.5: Installing stable google-api-core ---\")\n",
        "install_with_deps('google-api-core[grpc]~=2.11.1') # Or another stable 2.x like 2.15.0\n",
        "\n",
        "# 4. Verify critical packages before proceeding\n",
        "print(\"\\n--- Verification 1: Base packages ---\")\n",
        "importlib.invalidate_caches()\n",
        "import numpy\n",
        "import PIL\n",
        "import google.protobuf\n",
        "import google.api_core # Verify this new addition\n",
        "\n",
        "print(f\"NumPy version: {numpy.__version__}\")\n",
        "print(f\"Pillow version: {PIL.__version__}\")\n",
        "print(f\"Protobuf version: {google.protobuf.__version__}\")\n",
        "print(f\"google-api-core version: {google.api_core.__version__}\") # Check its version\n",
        "\n",
        "assert numpy.__version__ == \"1.26.4\", f\"NumPy version mismatch: {numpy.__version__}\"\n",
        "assert PIL.__version__ == \"9.5.0\", f\"Pillow version mismatch: {PIL.__version__}\"\n",
        "assert google.api_core.__version__.startswith(\"2.11.1\"), f\"google-api-core version mismatch: {google.api_core.__version__}\"\n",
        "\n",
        "# Test critical imports\n",
        "try:\n",
        "    from PIL import ImageFont\n",
        "    print(\"‚úÖ PIL.ImageFont imported successfully\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå PIL.ImageFont import failed: {e}\")\n",
        "    raise\n",
        "\n",
        "# 5. Install PyTorch with CUDA support\n",
        "print(\"\\n--- Step 3: Installing PyTorch stack ---\")\n",
        "torch_cmd = [sys.executable, '-m', 'pip', 'install',\n",
        "             'torch==2.2.1+cu118', 'torchvision==0.17.1+cu118',\n",
        "             'torchaudio==2.2.1+cu118',\n",
        "             '--index-url', 'https://download.pytorch.org/whl/cu118']\n",
        "subprocess.check_call(torch_cmd)\n",
        "\n",
        "# 6. Install transformers ecosystem with specific versions\n",
        "print(\"\\n--- Step 4: Installing Transformers stack ---\")\n",
        "# Quote version constraints to avoid shell interpretation\n",
        "subprocess.check_call([sys.executable, '-m', 'pip', 'install', \"transformers>=4.30.0,<4.41.0\"])\n",
        "subprocess.check_call([sys.executable, '-m', 'pip', 'install', \"huggingface-hub>=0.20.0\"])\n",
        "subprocess.check_call([sys.executable, '-m', 'pip', 'install', \"tokenizers>=0.14.0\"])\n",
        "\n",
        "# 7. Install ftfy before open-clip\n",
        "print(\"\\n--- Step 5: Installing ftfy and open-clip ---\")\n",
        "install_with_deps('ftfy>=6.0')\n",
        "force_install_package('open-clip-torch==2.23.0')\n",
        "\n",
        "# 8. Verify torch and open-clip\n",
        "print(\"\\n--- Verification 2: Torch and vision stack ---\")\n",
        "importlib.invalidate_caches()\n",
        "try:\n",
        "    import torch\n",
        "    import open_clip\n",
        "    print(f\"‚úÖ PyTorch version: {torch.__version__}\")\n",
        "    print(\"‚úÖ open-clip imported successfully\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Import error: {e}\")\n",
        "    raise\n",
        "\n",
        "# 9. Install Google Cloud Libraries\n",
        "print(\"\\n--- Step 6: Installing Google Generative AI ---\")\n",
        "install_with_deps('google-generativeai==0.5.2')\n",
        "# install_with_deps('google-cloud-vision~=3.4')\n",
        "\n",
        "# 10. Pre-install compatible versions for Whisper dependencies\n",
        "print(\"\\n--- Step 7: Pre-installing Whisper dependencies ---\")\n",
        "# Install numba compatible with numpy 1.26.4\n",
        "install_with_deps('numba==0.58.1')\n",
        "\n",
        "# Install spacy 3.4.4 to get thinc 8.1.x (compatible with numpy 1.26.4)\n",
        "# This prevents whisper from pulling thinc 8.3.6 which requires numpy 2.x\n",
        "install_with_deps('spacy==3.4.4')\n",
        "install_with_deps('thinc>=8.1.0,<8.2.0')\n",
        "\n",
        "# 11. Install Whisper\n",
        "print(\"\\n--- Step 8: Installing OpenAI Whisper ---\")\n",
        "install_with_deps('openai-whisper==20231117')\n",
        "\n",
        "# 12. Install remaining utilities\n",
        "print(\"\\n--- Step 9: Installing other utilities ---\")\n",
        "install_with_deps('ffmpeg-python==0.2.0')\n",
        "install_with_deps('opencv-python-headless==4.9.0.80')\n",
        "install_with_deps('nest-asyncio==1.6.0')\n",
        "\n",
        "# 13. Force reinstall our exact versions one more time to ensure they stick\n",
        "print(\"\\n--- Step 10: Final version enforcement ---\")\n",
        "force_install_package('numpy==1.26.4')\n",
        "force_install_package('Pillow==9.5.0')\n",
        "\n",
        "# 14. Final comprehensive verification\n",
        "print(\"\\n--- FINAL VERIFICATION ---\")\n",
        "importlib.invalidate_caches()\n",
        "\n",
        "overall_setup_ok_final = True\n",
        "\n",
        "def verify_import(module_name, version_attr='__version__', expected_version=None, critical=False):\n",
        "    global overall_setup_ok_final # Use the renamed global\n",
        "    try:\n",
        "        module = importlib.import_module(module_name)\n",
        "        version = getattr(module, version_attr, 'N/A')\n",
        "        status = \"‚úÖ\"\n",
        "        message = f\"{module_name}: {version}\"\n",
        "        if expected_version:\n",
        "            message += f\" (expected: {expected_version})\"\n",
        "            if version != expected_version:\n",
        "                status = \"‚ö†Ô∏è\"\n",
        "                if critical: overall_setup_ok_final = False # Fail build on critical mismatch\n",
        "        print(f\"{status} {message}\")\n",
        "\n",
        "        if module_name == \"PIL\" and expected_version == \"9.5.0\" and version == \"9.5.0\":\n",
        "             from PIL import ImageFont # Test only if Pillow is our target version\n",
        "             print(\"    ‚úÖ PIL.ImageFont works with Pillow 9.5.0\")\n",
        "        return True\n",
        "    except ImportError as e:\n",
        "        print(f\"‚ùå {module_name}: Import failed - {e}\")\n",
        "        if critical: overall_setup_ok_final = False\n",
        "        return False\n",
        "    except Exception as e_gen:\n",
        "        print(f\"‚ùå {module_name}: Verification error - {e_gen}\")\n",
        "        if critical: overall_setup_ok_final = False\n",
        "        return False\n",
        "\n",
        "# Critical version checks\n",
        "verify_import('PIL', expected_version='9.5.0', critical=True)\n",
        "verify_import('numpy', expected_version='1.26.4', critical=True)\n",
        "verify_import('google.api_core', expected_version='2.11.1', critical=True) # Verify pinned GAC\n",
        "\n",
        "# Other important checks\n",
        "verify_import('torch', expected_version='2.2.1+cu118')\n",
        "verify_import('transformers') # No strict version, just check import\n",
        "verify_import('huggingface_hub') # No strict version\n",
        "verify_import('open_clip')\n",
        "verify_import('whisper', expected_version='20231117') # package version\n",
        "verify_import('cv2')\n",
        "verify_import('google.generativeai', version_attr='VERSION', expected_version='0.5.2')\n",
        "# verify_import('google.cloud.vision') # Vision API client import (commented out)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "if overall_setup_ok_final:\n",
        "    print(\"‚úÖ Environment setup targeted critical versions. Check ‚ö†Ô∏è for non-critical or resolved versions.\")\n",
        "else:\n",
        "    print(\"‚ùå Critical issues remain in environment setup. Check errors above.\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Imports, API Key & Model Setup, Verifications\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import uuid\n",
        "import asyncio\n",
        "import importlib  # Added missing import\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any, List, Optional\n",
        "from IPython.display import display, Video, Markdown\n",
        "import io\n",
        "\n",
        "# Append /content to sys.path to ensure Colab can find our .py files\n",
        "if '/content' not in sys.path:\n",
        "    sys.path.append('/content')\n",
        "\n",
        "# Import custom utility functions\n",
        "# (Make sure you have uploaded these .py files to your Colab environment's /content/ directory)\n",
        "try:\n",
        "    import video\n",
        "    import models\n",
        "    import signals\n",
        "    import gemini\n",
        "    import fusion\n",
        "    print(\"‚úÖ Custom utility modules imported successfully.\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Error importing utility modules: {e}\")\n",
        "    print(\"Ensure helper files are uploaded to /content/ and have correct typing imports:\")\n",
        "    print(\"  - video.py needs: from typing import List, Tuple, Optional\")\n",
        "    print(\"  - models.py needs: from typing import List, Dict, Any, Optional\")\n",
        "    print(\"  - signals.py needs: from typing import List, Dict, Optional, Tuple, Any\")\n",
        "    print(\"  - gemini.py needs: from typing import List, Tuple, Any\")\n",
        "    raise  # Stop execution if utilities can't be imported\n",
        "\n",
        "# Standard ML/AI library imports\n",
        "import torch\n",
        "import numpy\n",
        "import PIL\n",
        "import open_clip\n",
        "import whisper\n",
        "import transformers\n",
        "import huggingface_hub\n",
        "import google.protobuf\n",
        "from google.cloud import vision\n",
        "import google.generativeai as genai\n",
        "import nest_asyncio\n",
        "\n",
        "# Apply nest_asyncio for running asyncio code in Colab cells\n",
        "nest_asyncio.apply()\n",
        "print(f\"\\nTorch CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"Current Python version: {sys.version.split()[0]}\")\n",
        "\n",
        "# --- AUTHENTICATE GOOGLE CLOUD SERVICES ---\n",
        "print(\"\\n--- Authenticating Google Cloud Services ---\")\n",
        "try:\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "    print(\"‚úÖ Google Cloud authentication successful\")\n",
        "\n",
        "    # Set the project ID\n",
        "    import os\n",
        "    os.environ['GOOGLE_CLOUD_PROJECT'] = 'fakecheck-461121'\n",
        "    print(\"‚úÖ Set Google Cloud project to: fakecheck-461121\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è Not running in Google Colab - please set up authentication manually\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error during Google Cloud authentication: {e}\")\n",
        "\n",
        "# --- Verification of Critical Library Versions ---\n",
        "print(\"\\n--- Verifying critical library versions after all imports ---\")\n",
        "critical_versions_ok = True\n",
        "\n",
        "def check_version(module_name_to_check, expected_version, actual_module_instance=None, version_attr='__version__'):\n",
        "    \"\"\"Check module version and report status\"\"\"\n",
        "    global critical_versions_ok\n",
        "    try:\n",
        "        # If actual_module_instance is provided, use it; otherwise import the module\n",
        "        if actual_module_instance is not None:\n",
        "            module = actual_module_instance\n",
        "        else:\n",
        "            module = importlib.import_module(module_name_to_check)\n",
        "\n",
        "        version = getattr(module, version_attr, 'N/A')\n",
        "\n",
        "        if expected_version:\n",
        "            if version == expected_version:\n",
        "                print(f\"‚úÖ {module_name_to_check} version: {version} (Matches target)\")\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è {module_name_to_check} version: {version} (Target: {expected_version} - MISMATCH!)\")\n",
        "                if module_name_to_check in [\"PIL\", \"numpy\"]:  # These are critical mismatches\n",
        "                    critical_versions_ok = False\n",
        "        else:\n",
        "            # No expected version provided, just print current version\n",
        "            print(f\"‚ÑπÔ∏è {module_name_to_check} version: {version}\")\n",
        "\n",
        "    except ImportError:\n",
        "        print(f\"‚ùå {module_name_to_check} not imported for version check.\")\n",
        "        critical_versions_ok = False\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error checking version for {module_name_to_check}: {e}\")\n",
        "        critical_versions_ok = False\n",
        "\n",
        "# Check critical versions\n",
        "check_version(\"PIL\", \"9.5.0\", actual_module_instance=PIL)\n",
        "try:\n",
        "    from PIL import ImageFont\n",
        "    print(\"    ‚úÖ PIL.ImageFont imported successfully (Pillow integrity check).\")\n",
        "except ImportError as e_font:\n",
        "    print(f\"    ‚ùå PIL.ImageFont import ERROR: {e_font}\")\n",
        "    critical_versions_ok = False\n",
        "\n",
        "check_version(\"numpy\", \"1.26.4\", actual_module_instance=numpy)\n",
        "check_version(\"torch\", \"2.2.1+cu118\", actual_module_instance=torch)\n",
        "\n",
        "# For these, we don't enforce specific versions anymore\n",
        "check_version(\"transformers\", expected_version=None, actual_module_instance=transformers)\n",
        "check_version(\"huggingface_hub\", expected_version=None, actual_module_instance=huggingface_hub)\n",
        "check_version(\"google.protobuf\", expected_version=None, actual_module_instance=google.protobuf)\n",
        "check_version(\"open_clip\", expected_version=None, actual_module_instance=open_clip)\n",
        "check_version(\"whisper\", expected_version=\"1.1.10\", actual_module_instance=whisper)\n",
        "check_version(\"google.generativeai\", expected_version=\"0.5.2\", actual_module_instance=genai, version_attr='__version__')\n",
        "\n",
        "# For google.cloud.vision, check if it's importable\n",
        "try:\n",
        "    import google.cloud.vision\n",
        "    print(\"‚ÑπÔ∏è google.cloud.vision: Imported successfully\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå google.cloud.vision: Import failed - {e}\")\n",
        "    critical_versions_ok = False\n",
        "\n",
        "if not critical_versions_ok:\n",
        "    print(\"üî•üî•üî• WARNING: Critical Pillow or NumPy versions do not match targets. This may lead to errors.\")\n",
        "\n",
        "# --- Load API Keys & Initialize Models ---\n",
        "print(\"\\n--- Configuring Models and API Keys ---\")\n",
        "GEMINI_API_KEY = None\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "    if not GEMINI_API_KEY:\n",
        "        print(\"‚ö†Ô∏è GEMINI_API_KEY not found in Colab Secrets. Gemini features will be disabled.\")\n",
        "    else:\n",
        "        genai.configure(api_key=GEMINI_API_KEY)\n",
        "        print(\"‚úÖ Gemini API configured for Generative AI.\")\n",
        "except ImportError:  # Not in Colab\n",
        "    GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
        "    if GEMINI_API_KEY:\n",
        "        genai.configure(api_key=GEMINI_API_KEY)\n",
        "        print(\"‚úÖ Gemini API configured from OS env.\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è GEMINI_API_KEY OS environment variable not found.\")\n",
        "\n",
        "# Device selection\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# Initialize models (this can take a moment)\n",
        "CLIP_MODEL, CLIP_PREPROCESS_FN = None, None\n",
        "try:\n",
        "    CLIP_MODEL, _, CLIP_PREPROCESS_FN = open_clip.create_model_and_transforms(\n",
        "        \"ViT-L-14\", pretrained=\"laion2b_s32b_b82k\", device=DEVICE\n",
        "    )\n",
        "    CLIP_MODEL.eval()\n",
        "    print(\"‚úÖ CLIP Model (ViT-L-14) loaded.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading CLIP model: {e}\")\n",
        "\n",
        "WHISPER_ASR_MODEL = None\n",
        "try:\n",
        "    WHISPER_ASR_MODEL = whisper.load_model(\"base.en\", device=DEVICE)\n",
        "    print(\"‚úÖ Whisper Model (base.en) loaded.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading Whisper model: {e}\")\n",
        "    if \"numpy.dtype size changed\" in str(e):\n",
        "        print(\"    This Whisper load error is likely due to a NumPy ABI mismatch. Ensure NumPy 1.26.4 is active.\")\n",
        "\n",
        "GEMINI_MODEL_INSTANCE = None\n",
        "if GEMINI_API_KEY:\n",
        "    try:\n",
        "        GEMINI_MODEL_INSTANCE = genai.GenerativeModel(\"gemini-2.5-pro-preview-05-06\")\n",
        "        print(f\"‚úÖ Gemini Model ('{GEMINI_MODEL_INSTANCE.model_name}') initialized for generative tasks.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error initializing Gemini model: {e}\")\n",
        "else:\n",
        "    print(\"‚è© Gemini generative model not initialized (API key missing/config error).\")\n",
        "\n",
        "VISION_API_CLIENT = None\n",
        "try:\n",
        "    VISION_API_CLIENT = vision.ImageAnnotatorClient()\n",
        "    print(\"‚úÖ Google Cloud Vision API client initialized.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error initializing Google Cloud Vision API client: {e}\")\n",
        "    print(\"   Ensure you have authenticated with 'auth.authenticate_user()' above\")\n",
        "    print(\"   and that the Vision API is enabled in your GCP project.\")\n",
        "\n",
        "# Check if all essential models for the current pipeline are loaded\n",
        "essential_models_loaded_simplified = all([CLIP_MODEL, WHISPER_ASR_MODEL, VISION_API_CLIENT])\n",
        "\n",
        "if not essential_models_loaded_simplified:\n",
        "    print(\"üî•üî•üî• WARNING: One or more essential ML/Cloud models (CLIP, Whisper, Vision API) failed to load.\")\n",
        "    print(\"     Pipeline will be severely limited or fail.\")\n",
        "else:\n",
        "    print(\"‚úÖ‚úÖ‚úÖ All currently essential models/clients appear to be initialized.\")\n",
        "\n",
        "# Print final status\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ENVIRONMENT STATUS SUMMARY:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"‚úì Pillow 9.5.0: {'YES' if PIL.__version__ == '9.5.0' else 'NO - ' + PIL.__version__}\")\n",
        "print(f\"‚úì NumPy 1.26.4: {'YES' if numpy.__version__ == '1.26.4' else 'NO - ' + numpy.__version__}\")\n",
        "print(f\"‚úì CLIP Model: {'YES' if CLIP_MODEL else 'NO'}\")\n",
        "print(f\"‚úì Whisper Model: {'YES' if WHISPER_ASR_MODEL else 'NO'}\")\n",
        "print(f\"‚úì Vision API: {'YES' if VISION_API_CLIENT else 'NO'}\")\n",
        "print(f\"‚úì Gemini Model: {'YES' if GEMINI_MODEL_INSTANCE else 'NO (optional)'}\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "2VApthe7mZPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a0c7028-34c3-47d4-efb3-ecd267ee1768"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Custom utility modules imported successfully.\n",
            "\n",
            "Torch CUDA available: True\n",
            "Current Python version: 3.11.12\n",
            "\n",
            "--- Authenticating Google Cloud Services ---\n",
            "‚úÖ Google Cloud authentication successful\n",
            "‚úÖ Set Google Cloud project to: fakecheck-461121\n",
            "\n",
            "--- Verifying critical library versions after all imports ---\n",
            "‚úÖ PIL version: 9.5.0 (Matches target)\n",
            "    ‚úÖ PIL.ImageFont imported successfully (Pillow integrity check).\n",
            "‚úÖ numpy version: 1.26.4 (Matches target)\n",
            "‚úÖ torch version: 2.2.1+cu118 (Matches target)\n",
            "‚ÑπÔ∏è transformers version: 4.40.2\n",
            "‚ÑπÔ∏è huggingface_hub version: 0.31.4\n",
            "‚ÑπÔ∏è google.protobuf version: 4.25.7\n",
            "‚ÑπÔ∏è open_clip version: N/A\n",
            "‚ö†Ô∏è whisper version: 20231117 (Target: 1.1.10 - MISMATCH!)\n",
            "‚úÖ google.generativeai version: 0.5.2 (Matches target)\n",
            "‚ÑπÔ∏è google.cloud.vision: Imported successfully\n",
            "\n",
            "--- Configuring Models and API Keys ---\n",
            "‚úÖ Gemini API configured for Generative AI.\n",
            "Using device: cuda\n",
            "‚úÖ CLIP Model (ViT-L-14) loaded.\n",
            "‚úÖ Whisper Model (base.en) loaded.\n",
            "‚úÖ Gemini Model ('models/gemini-2.5-pro-preview-05-06') initialized for generative tasks.\n",
            "‚úÖ Google Cloud Vision API client initialized.\n",
            "‚úÖ‚úÖ‚úÖ All currently essential models/clients appear to be initialized.\n",
            "\n",
            "============================================================\n",
            "ENVIRONMENT STATUS SUMMARY:\n",
            "============================================================\n",
            "‚úì Pillow 9.5.0: YES\n",
            "‚úì NumPy 1.26.4: YES\n",
            "‚úì CLIP Model: YES\n",
            "‚úì Whisper Model: YES\n",
            "‚úì Vision API: YES\n",
            "‚úì Gemini Model: YES\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Helper function to run async code from notebook ---\n",
        "def awaitable(coroutine_to_run):\n",
        "    try:\n",
        "        loop = asyncio.get_running_loop()\n",
        "        return loop.run_until_complete(coroutine_to_run)\n",
        "    except RuntimeError: # No event loop running\n",
        "        return asyncio.run(coroutine_to_run)"
      ],
      "metadata": {
        "id": "fJnFXJSSmj63"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Main Detection Pipeline Function\n",
        "\n",
        "import numpy as np  # Add this import for np alias\n",
        "\n",
        "async def run_full_deepfake_detection(\n",
        "    video_file_path: str,\n",
        "    output_dir_base: str = \"/content/detections\"  # Output directory in Colab\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Main simplified deepfake detection pipeline.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(video_file_path):\n",
        "        return {\"error\": f\"Input video not found: {video_file_path}\"}\n",
        "\n",
        "    video_basename = os.path.basename(video_file_path)\n",
        "    run_id = f\"{os.path.splitext(video_basename)[0]}_{uuid.uuid4().hex[:6]}\"\n",
        "    # output_dir = os.path.join(output_dir_base, run_id)  # No overlay, so dir might not be used much\n",
        "    # os.makedirs(output_dir, exist_ok=True)  # Create if we save other artifacts later\n",
        "\n",
        "    detection_results = {\n",
        "        \"input_video\": video_basename,\n",
        "        \"run_id\": run_id,\n",
        "        \"pipeline_version\": \"simplified_v1_cloud_vision_blinks\" # Change back to simplified_v1_cloud_vision_blinks when using google-vision-api\n",
        "    }\n",
        "    temp_audio_path: Optional[str] = None\n",
        "    processed_frames_pil: List[PIL.Image.Image] = []\n",
        "\n",
        "    try:\n",
        "        print(f\"\\nProcessing: {video_basename}\")\n",
        "        # 1. Sample Video & Audio\n",
        "        target_fps = 8  # FPS for internal processing for CLIP/Whisper\n",
        "        max_video_duration = 30  # seconds\n",
        "\n",
        "        processed_frames_pil, temp_audio_path, original_duration, processed_duration = \\\n",
        "            video.sample_video_content(video_file_path,\n",
        "                                                target_fps=target_fps,\n",
        "                                                max_duration_sec=max_video_duration)\n",
        "\n",
        "        detection_results[\"video_original_duration_sec\"] = round(original_duration, 2)\n",
        "        detection_results[\"video_processed_duration_sec\"] = round(processed_duration, 2)\n",
        "        detection_results[\"num_frames_sampled_for_clip_whisper\"] = len(processed_frames_pil)\n",
        "\n",
        "        if not processed_frames_pil:\n",
        "            raise RuntimeError(\"Frame sampling returned no frames.\")\n",
        "\n",
        "        # 2. CLIP Visual Score\n",
        "        score_visual_clip = 0.0  # Default if model fails\n",
        "        if CLIP_MODEL and CLIP_PREPROCESS_FN:\n",
        "            score_visual_clip = models.calculate_visual_clip_score(\n",
        "                processed_frames_pil, CLIP_MODEL, CLIP_PREPROCESS_FN, DEVICE\n",
        "            )\n",
        "        detection_results[\"score_visual_clip\"] = round(score_visual_clip, 3)\n",
        "\n",
        "        # 3. Whisper ASR\n",
        "        transcription_text = \"\"\n",
        "        if WHISPER_ASR_MODEL and temp_audio_path:\n",
        "            transcription_data = models.transcribe_audio_content(\n",
        "                temp_audio_path, WHISPER_ASR_MODEL\n",
        "            )\n",
        "            transcription_text = transcription_data[\"text\"]\n",
        "        detection_results[\"transcript_snippet\"] = transcription_text[:150] + \"...\" if transcription_text else \"[No Speech/Audio Error]\"\n",
        "\n",
        "        # BERT Score Removed\n",
        "\n",
        "        # rPPG Score Removed\n",
        "\n",
        "        # Commented out until Google Vision API usage is fixed\n",
        "        # # 4. Eye Blink Score (using Google Cloud Vision API)\n",
        "        # score_blink = 0.5  # Neutral default\n",
        "        # if VISION_API_CLIENT and processed_frames_pil:\n",
        "        #     # TEMPORARY: Only send 1 frame for testing\n",
        "        #     print(\"\\n‚ö†Ô∏è TESTING MODE: Sending only 1 frame to Vision API\")\n",
        "\n",
        "        #     # Select middle frame for testing\n",
        "        #     test_frame_index = len(processed_frames_pil) // 2\n",
        "        #     frames_for_vision_api_pil = [processed_frames_pil[test_frame_index]]\n",
        "\n",
        "        #     # Original code for reference (commented out for testing):\n",
        "        #     # MAX_FRAMES_FOR_VISION_API = 30\n",
        "        #     # frames_for_vision_api_pil: List[PIL.Image.Image]\n",
        "        #     # if len(processed_frames_pil) > MAX_FRAMES_FOR_VISION_API:\n",
        "        #     #     indices = np.linspace(0, len(processed_frames_pil) - 1, MAX_FRAMES_FOR_VISION_API, dtype=int)\n",
        "        #     #     frames_for_vision_api_pil = [processed_frames_pil[i] for i in indices]\n",
        "        #     # else:\n",
        "        #     #     frames_for_vision_api_pil = processed_frames_pil\n",
        "\n",
        "        #     frames_for_vision_api_bytes: List[bytes] = []\n",
        "        #     for frame_pil_img in frames_for_vision_api_pil:\n",
        "        #         byte_arr = io.BytesIO()\n",
        "        #         frame_pil_img.save(byte_arr, format='JPEG', quality=85)\n",
        "        #         frames_for_vision_api_bytes.append(byte_arr.getvalue())\n",
        "\n",
        "        #     print(f\"Sending {len(frames_for_vision_api_bytes)} frame(s) to Google Cloud Vision API for blink detection...\", file=sys.stderr)\n",
        "\n",
        "        #     # The duration for blink rate calculation should be the duration spanned by frames_for_vision_api_pil\n",
        "        #     # For testing with 1 frame, we'll use a small duration\n",
        "        #     blink_segment_duration = 0.125  # 1/8 second for single frame test\n",
        "\n",
        "        #     # Original duration calculation (commented out for testing):\n",
        "        #     # blink_segment_duration = processed_duration\n",
        "\n",
        "        #     # Call the async helper function\n",
        "        #     try:\n",
        "        #         vision_landmarks_per_frame = await signals.get_eye_landmarks_from_vision_api(\n",
        "        #             frames_for_vision_api_bytes, VISION_API_CLIENT\n",
        "        #         )\n",
        "\n",
        "        #         if vision_landmarks_per_frame:  # Check if any landmarks were returned\n",
        "        #             print(f\"‚úÖ Vision API returned landmarks for {len(vision_landmarks_per_frame)} frame(s)\")\n",
        "        #             score_blink = signals.calculate_blink_score_from_vision_api(\n",
        "        #                 vision_landmarks_per_frame,\n",
        "        #                 video_segment_duration_sec=blink_segment_duration\n",
        "        #             )\n",
        "        #         else:\n",
        "        #             print(\"‚ö†Ô∏è Vision API returned no landmarks\")\n",
        "        #     except Exception as e:\n",
        "        #         print(f\"‚ùå Vision API call failed: {str(e)}\")\n",
        "        #         import traceback\n",
        "        #         traceback.print_exc()\n",
        "\n",
        "        # detection_results[\"score_blink_rate_vision_api\"] = round(score_blink, 3)\n",
        "\n",
        "        # 4. Gemini Inspections (Visual, Lipsync, AND Blinks)\n",
        "        flag_gemini_visual, flag_gemini_lipsync, flag_gemini_blinks = 0, 0, 0 # Defaults\n",
        "        if GEMINI_MODEL_INSTANCE:\n",
        "            # Ensure 'gemini' module (gemini.py) is used\n",
        "            flag_gemini_visual, flag_gemini_lipsync, flag_gemini_blinks = \\\n",
        "                await gemini.run_gemini_inspections(\n",
        "                    processed_frames_pil, video_file_path, transcription_text, GEMINI_MODEL_INSTANCE\n",
        "                )\n",
        "        detection_results[\"flag_gemini_visual_artifact\"] = flag_gemini_visual\n",
        "        detection_results[\"flag_gemini_lipsync_issue\"] = flag_gemini_lipsync\n",
        "        detection_results[\"flag_gemini_abnormal_blinks\"] = flag_gemini_blinks # New flag\n",
        "\n",
        "        # 5. Fuse Scores\n",
        "        # Ensure 'fusion' module (fusion.py) is used\n",
        "        final_confidence, final_label, anomaly_tags_list = fusion.fuse_detection_scores(\n",
        "            score_visual_clip,\n",
        "            flag_gemini_visual,\n",
        "            flag_gemini_lipsync,\n",
        "            flag_gemini_blinks # Pass the new Gemini blink flag\n",
        "        )\n",
        "        detection_results[\"deepfake_confidence_overall\"] = final_confidence\n",
        "        detection_results[\"final_predicted_label\"] = final_label\n",
        "        detection_results[\"anomaly_tags_detected\"] = anomaly_tags_list\n",
        "\n",
        "        detection_results[\"overlay_video_path\"] = \"N/A (Overlay generation removed)\"\n",
        "\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        error_message = f\"Pipeline error for {video_basename}: {str(e)}\"\n",
        "        print(f\"{error_message}\\n{traceback.format_exc()}\", file=sys.stderr)\n",
        "        detection_results[\"error\"] = error_message\n",
        "    finally:\n",
        "        if temp_audio_path and os.path.exists(temp_audio_path):\n",
        "            try: os.remove(temp_audio_path)\n",
        "            except OSError: pass\n",
        "\n",
        "    return detection_results\n"
      ],
      "metadata": {
        "id": "sEPKpmximnAj"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4 : Example Usage  (visual-artifact check only)\n",
        "\n",
        "from pathlib import Path\n",
        "import os, sys, time, json, asyncio, importlib\n",
        "from IPython.display import Markdown\n",
        "import gemini                      # module with v1.7 code\n",
        "importlib.reload(gemini)           # ensure fresh version every run\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Monkey-patch gemini.run_gemini_inspections only once\n",
        "# ------------------------------------------------------------------\n",
        "if not getattr(gemini, \"_visual_only_patched\", False):\n",
        "    _orig_runner = gemini.run_gemini_inspections\n",
        "\n",
        "    async def _visual_only(frames, video, transcript, model, **kwargs):\n",
        "        return await _orig_runner(\n",
        "            frames, video, transcript, model,\n",
        "            enable_visual_artifacts=True,\n",
        "            enable_lipsync=True,\n",
        "            enable_abnormal_blinks=True,\n",
        "        )\n",
        "\n",
        "    gemini.run_gemini_inspections = _visual_only\n",
        "    gemini._visual_only_patched = True   # sentinel to avoid double-patch\n",
        "# ------------------------------------------------------------------\n",
        "\n",
        "# --- Choose / validate test video ---------------------------------\n",
        "Path(\"/content/videos_for_testing\").mkdir(parents=True, exist_ok=True)\n",
        "TEST_VIDEO_PATH = \"/content/videos_for_testing/Puppramin.mp4\"\n",
        "\n",
        "if not os.path.exists(TEST_VIDEO_PATH) or os.path.getsize(TEST_VIDEO_PATH) < 1000:\n",
        "    sample = \"/usr/local/lib/python3.10/dist-packages/google/colab/files/video_player_test.mp4\"\n",
        "    if os.path.exists(sample) and os.path.getsize(sample) > 1000:\n",
        "        print(f\"Using Colab sample video: {sample}\")\n",
        "        TEST_VIDEO_PATH = sample\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è  No valid test video. Upload one to {TEST_VIDEO_PATH}.\", file=sys.stderr)\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "async def run_pipeline_and_display():\n",
        "    if not (os.path.exists(TEST_VIDEO_PATH) and os.path.getsize(TEST_VIDEO_PATH) > 1000):\n",
        "        display(Markdown(\"### ‚ö†Ô∏è Pipeline aborted ‚Äì missing test video\"))\n",
        "        return\n",
        "\n",
        "    # verify Cell 1 models\n",
        "    if not all([CLIP_MODEL, WHISPER_ASR_MODEL, GEMINI_MODEL_INSTANCE]):\n",
        "        display(Markdown(\"### ‚ö†Ô∏è Pipeline aborted ‚Äì models not initialised\"))\n",
        "        return\n",
        "\n",
        "    print(f\"\\n>>> Starting detection for: {TEST_VIDEO_PATH} <<<\")\n",
        "    t0 = time.time()\n",
        "\n",
        "    result = await run_full_deepfake_detection(TEST_VIDEO_PATH)\n",
        "\n",
        "    result[\"notebook_total_processing_time_sec\"] = round(time.time() - t0, 2)\n",
        "\n",
        "    display(Markdown(\"#### Final result\"))\n",
        "    display(Markdown(f\"```json\\n{json.dumps(result, indent=2)}\\n```\"))\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "if __name__ == \"__main__\" and \"google.colab\" in sys.modules:\n",
        "    print(\"Running detection pipeline demo (visual-artifact Gemini check only)‚Ä¶\")\n",
        "\n",
        "    if 'awaitable' not in globals():\n",
        "        def awaitable(coro):\n",
        "            try:\n",
        "                loop = asyncio.get_running_loop()\n",
        "                return loop.run_until_complete(coro)\n",
        "            except RuntimeError:\n",
        "                return asyncio.run(coro)\n",
        "\n",
        "    awaitable(run_pipeline_and_display())\n",
        "    print(\"\\nDemo finished. Check results above.\")\n",
        "\n",
        "\n",
        "# # --- Define video path for testing ---\n",
        "# # Option A: Upload a video manually to /content/ and set its path here\n",
        "# # e.g., from google.colab import files; uploaded = files.upload()\n",
        "# # TEST_VIDEO_PATH = list(uploaded.keys())[0]\n",
        "\n",
        "# # Option B: Place video in /content/videos_for_testing/\n",
        "# Path(\"/content/videos_for_testing\").mkdir(parents=True, exist_ok=True)\n",
        "# # TEST_VIDEO_PATH = \"/content/videos_for_testing/fake_test.mp4\"  # <--- CHANGE THIS TO YOUR UPLOADED VIDEO\n",
        "# TEST_VIDEO_PATH = \"/content/videos_for_testing/Puppramin.mp4\"  # <--- CHANGE THIS TO YOUR UPLOADED VIDEO\n",
        "\n",
        "# # Check if the test video exists, otherwise try a Colab default or inform user\n",
        "# if not os.path.exists(TEST_VIDEO_PATH) or os.path.getsize(TEST_VIDEO_PATH) < 1000 : # Min 1KB\n",
        "#     print(f\"Test video '{TEST_VIDEO_PATH}' not found, empty, or too small.\", file=sys.stderr)\n",
        "#     # Attempt to find a Colab sample if primary test video isn't there\n",
        "#     colab_default_samples = [\n",
        "#         '/usr/local/lib/python3.10/dist-packages/google/colab/files/video_player_test.mp4', # Common path\n",
        "#         # Add other potential Colab sample paths if known\n",
        "#     ]\n",
        "#     found_sample = False\n",
        "#     for sample_path in colab_default_samples:\n",
        "#         if os.path.exists(sample_path) and os.path.getsize(sample_path) > 1000:\n",
        "#             TEST_VIDEO_PATH = sample_path\n",
        "#             print(f\"Using Colab default sample video for demo: {TEST_VIDEO_PATH}\")\n",
        "#             found_sample = True\n",
        "#             break\n",
        "#     if not found_sample:\n",
        "#         print(f\"No valid test video found. Please upload a video to '{TEST_VIDEO_PATH}' (or similar) and update the path.\")\n",
        "#         # To allow the rest of the cell to run without immediate error if no video,\n",
        "#         # but the pipeline itself will fail if TEST_VIDEO_PATH is not valid.\n",
        "#         if not os.path.exists(TEST_VIDEO_PATH): Path(TEST_VIDEO_PATH).touch() # Creates an empty file\n",
        "\n",
        "# async def run_pipeline_and_display():\n",
        "#     if not (os.path.exists(TEST_VIDEO_PATH) and os.path.getsize(TEST_VIDEO_PATH) > 1000): # Check if file > 1KB\n",
        "#         display(Markdown(f\"### ‚ö†Ô∏è Pipeline Aborted \\n**Reason:** Test video at `{TEST_VIDEO_PATH}` is not valid or too small. Please upload a real video and update the path.\"))\n",
        "#         return\n",
        "\n",
        "#     # Check if essential models from Cell 1 loaded correctly\n",
        "#     current_essential_models = all([CLIP_MODEL, WHISPER_ASR_MODEL, GEMINI_MODEL_INSTANCE])\n",
        "\n",
        "#     if not current_essential_models:\n",
        "#         missing_models_str = []\n",
        "#         if not CLIP_MODEL: missing_models_str.append(\"CLIP_MODEL\")\n",
        "#         if not WHISPER_ASR_MODEL: missing_models_str.append(\"WHISPER_ASR_MODEL\")\n",
        "#         if not GEMINI_MODEL_INSTANCE: missing_models_str.append(\"GEMINI_MODEL_INSTANCE (needed for blinks and other checks)\")\n",
        "#         display(Markdown(f\"### ‚ö†Ô∏è Pipeline Aborted \\n**Reason:** Not all essential models/clients were initialized successfully in Cell 1: {', '.join(missing_models_str)}. Please check errors in Cell 1.\"))\n",
        "#         return\n",
        "\n",
        "#     print(f\"\\n>>> Starting detection for: {TEST_VIDEO_PATH} <<<\")\n",
        "#     start_time_total = time.time()\n",
        "\n",
        "#     # Since run_full_deepfake_detection is async, we can await it directly\n",
        "#     result = await run_full_deepfake_detection(TEST_VIDEO_PATH)\n",
        "\n",
        "#     end_time_total = time.time()\n",
        "#     result[\"notebook_total_processing_time_sec\"] = round(end_time_total - start_time_total, 2)\n",
        "\n",
        "#     print(\"\\n--- FINAL DETECTION RESULT (Notebook) ---\")\n",
        "#     # Pretty print JSON\n",
        "#     display(Markdown(f\"```json\\n{json.dumps(result, indent=2)}\\n```\"))\n",
        "\n",
        "#     if \"error\" in result:\n",
        "#         display(Markdown(f\"\\n**‚ö†Ô∏è An error occurred during processing:** {result['error']}\"))\n",
        "#     else:\n",
        "#         display(Markdown(f\"\\n**Processed Video:** `{result.get('input_video', 'N/A')}`\"))\n",
        "#         display(Markdown(f\"**Predicted Label:** `{result.get('final_predicted_label', 'N/A')}`\"))\n",
        "#         display(Markdown(f\"**Overall Deepfake Confidence:** `{result.get('deepfake_confidence_overall', 'N/A')}`\"))\n",
        "#         display(Markdown(f\"**Anomaly Tags:** `{', '.join(result.get('anomaly_tags_detected', [])) if result.get('anomaly_tags_detected') else 'None'}`\"))\n",
        "\n",
        "# # Run the main processing and display\n",
        "# if __name__ == \"__main__\" and \"google.colab\" in sys.modules:\n",
        "#     print(\"Running detection pipeline demo...\")\n",
        "\n",
        "#     # Use the awaitable helper from Cell 2 to run the async function\n",
        "#     # If awaitable is not defined in this scope, use it from globals or redefine\n",
        "#     if 'awaitable' not in globals():\n",
        "#         def awaitable(coroutine_to_run):\n",
        "#             try:\n",
        "#                 loop = asyncio.get_running_loop()\n",
        "#                 return loop.run_until_complete(coroutine_to_run)\n",
        "#             except RuntimeError:\n",
        "#                 return asyncio.run(coroutine_to_run)\n",
        "#             except Exception as e:\n",
        "#                 import traceback\n",
        "#                 traceback.print_exc()\n",
        "#                 display(Markdown(f\"**‚ö†Ô∏è Uncaught exception during pipeline:** {str(e)}\"))\n",
        "\n",
        "#     # Run the async function using awaitable\n",
        "#     awaitable(run_pipeline_and_display())\n",
        "\n",
        "#     print(\"\\nDemo finished. Check results above.\")\n",
        "#     print(f\"Output files (if any, like logs) might be in subdirectories under /content/detections/\")"
      ],
      "metadata": {
        "id": "mpAeWa1BmrdN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "outputId": "92d2e319-69be-4b82-c1e9-658354f2e20d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running detection pipeline demo (visual-artifact Gemini check only)‚Ä¶\n",
            "\n",
            ">>> Starting detection for: /content/videos_for_testing/Puppramin.mp4 <<<\n",
            "\n",
            "Processing: Puppramin.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Info: Original video duration 72.17s exceeds max_duration_sec 30s. Processing only the first 30.00s.\n",
            "FFmpeg extracted 240 frames (target max: 240).\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [00:01<00:00, 2497.05frames/s]\n",
            "GEMINI_REPLY (gemini_check_visual_artifacts): NO\n",
            "GEMINI_WARN: connection reset ‚Äì retry 1/2 in 3s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "#### Final result"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```json\n{\n  \"input_video\": \"Puppramin.mp4\",\n  \"run_id\": \"Puppramin_7378a3\",\n  \"pipeline_version\": \"simplified_v1_cloud_vision_blinks\",\n  \"video_original_duration_sec\": 72.17,\n  \"video_processed_duration_sec\": 30.0,\n  \"num_frames_sampled_for_clip_whisper\": 240,\n  \"score_visual_clip\": 0.56,\n  \"transcript_snippet\": \"I tried everything from my depression. Nothing worked. Every day felt heavy. I felt trapped. Then I tried pup-er-min. Our prescription helps your body...\",\n  \"flag_gemini_visual_artifact\": 0,\n  \"flag_gemini_lipsync_issue\": 1,\n  \"flag_gemini_abnormal_blinks\": 1,\n  \"deepfake_confidence_overall\": 0.574,\n  \"final_predicted_label\": \"UNCERTAIN\",\n  \"anomaly_tags_detected\": [\n    \"GEMINI_LIPSYNC_ISSUE\",\n    \"GEMINI_ABNORMAL_BLINKS\"\n  ],\n  \"overlay_video_path\": \"N/A (Overlay generation removed)\",\n  \"notebook_total_processing_time_sec\": 135.69\n}\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Demo finished. Check results above.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JNjw3ft5qPn8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}